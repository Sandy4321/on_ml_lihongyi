# -*- org-export-babel-evaluate: nil -*-
#+PROPERTY: header-args :eval never-export
#+PROPERTY: header-args:python :session title
#+PROPERTY: header-args:ipython :session title
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="/home/yiddi/git_repos/YIDDI_org_export_theme/theme/org-nav-theme_cache.css" >
#+HTML_HEAD: <script src="https://hypothes.is/embed.js" async></script>
#+HTML_HEAD: <script type="application/json" class="js-hypothesis-config">
#+HTML_HEAD: <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
#+OPTIONS: html-link-use-abs-url:nil html-postamble:nil html-preamble:t
#+OPTIONS: H:3 num:t ^:nil _:nil tags:not-in-toc
#+TITLE: 李宏毅RL第6课: QLearning on continuous action
#+AUTHOR: yiddishkop
#+EMAIL: [[mailto:yiddishkop@163.com][yiddi's email]]
#+TAGS: {PKGIMPT(i) DATAVIEW(v) DATAPREP(p) GRAPHBUILD(b) GRAPHCOMPT(c)} LINAGAPI(a) PROBAPI(b) MATHFORM(f) MLALGO(m)


跟 Policy Gradient 比起来, Q-Learning 是比较稳定的比较好的, Policy Gradient 用在
游戏上其实不太玩的起来. 但是 Q-Learning 最大的问题是不太容易处理连续 action.



#+DOWNLOADED: /tmp/screenshot.png @ 2018-08-27 00:42:34
[[file:screenshot_2018-08-27_00-42-34.png]]


#+DOWNLOADED: /tmp/screenshot.png @ 2018-08-27 00:47:16
[[file:screenshot_2018-08-27_00-47-16.png]]
